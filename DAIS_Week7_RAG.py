import streamlit as st
import json
import uuid
from base64 import b64decode
import sys
import pysqlite3
sys.modules["sqlite3"] = pysqlite3
from langchain_community.vectorstores import Chroma
# from langchain.storage import InMemoryStore
from langchain_core.stores import InMemoryStore
# from langchain.schema import Document
from langchain_core.documents import Document
# from langchain.retrievers.multi_vector import MultiVectorRetriever
from langchain_classic.retrievers.multi_vector import MultiVectorRetriever
# from langchain_community.retrievers.multi_vector import MultiVectorRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
# from langchain_together import ChatTogether
from langchain_groq import ChatGroq
from langchain_community.chat_models import ChatHuggingFace
#from langchain_community.chat_models import ChatPerplexity
from langchain_anthropic import ChatAnthropic
from langchain_perplexity import ChatPerplexity
#from langchain.prompts import ChatPromptTemplate
from langchain_classic.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import SentenceTransformer
# from langchain.schema import Document
from langchain_classic.schema import Document
import traceback
from operator import itemgetter
import torch
import os

os.environ["PYTORCH_ENABLE_META_TENSOR"] = "0"

st.title("Course : Digital AI strategy")

st.subheader ("Week 7:  New Business Models as digital AI Strategy & Finding Platform in Products")

# Sidebar: Choose provider & keys
provider = st.sidebar.selectbox(
    "Choose LLM Provider:",
    ("OpenAI", # "Together", 
     "Groq", "Hugging Face", "Anthropic", "Perplexity")
)
api_key = st.sidebar.text_input(f"{provider} API Key", type="password")
model_name = st.sidebar.text_input("Model name (optional)", "")

# Spacer to push warning downward (optional)
st.sidebar.markdown("<br><br><br>", unsafe_allow_html=True)

# AI warning box at bottom
st.sidebar.markdown(
    """
    <div style='
        border: 1px solid red;
        background-color: #ffe6e6;
        color: red;
        padding: 10px;
        font-size: 0.85em;
        border-radius: 5px;
        margin-top: 30px;
    '>
        ‚ö†Ô∏è This is an AI chat bot. Use caution when interpreting its responses. ‚ö†Ô∏è
    </div>
    """,
    unsafe_allow_html=True,
)

### Change the below chroma DB path for changing the the vector DB

# Load prebuilt chroma DB path 
PERSIST_DIRECTORY = "./Week_7_03Nov2025"

### --------------------

# Sample Questions Section - Available without API key
# Modified Sample Questions Section - Platform Strategy Focus with Learning Intents


with st.expander("üí° Sample Questions", expanded=False):
    st.markdown("### Get started with these example questions on **Digital AI Strategy Implementation**:")

    # Easy Explainer (Focus on simple definitions and core concepts)
    st.markdown("üë∂ **Easy Explainer: Core Concepts**")
    col1, col2 = st.columns(2)

    with col1:
        if st.button("üîÑ Explain the 10-building block Framework taught in this session", key="easy_q1_s7"):
            if 'sample_question' not in st.session_state:
                st.session_state.sample_question = None
            # Question 1: Digital Strategy Implementation Framework
            st.session_state.sample_question = "What is the primary purpose of the 10-building block Digital Strategy Implementation Framework, and which three blocks are most critical?"

    with col2:
        if st.button("üîó Explain Star Model‚Ñ¢ Simply", key="easy_q2_s7"):
            if 'sample_question' not in st.session_state:
                st.session_state.sample_question = None
            # Question 2: Jay R. Galbraith's Star Model‚Ñ¢
            st.session_state.sample_question = "What are the five points of Jay R. Galbraith's Star Model‚Ñ¢ for organizational design , and which two elements typically present the greatest challenge during a digital transformation?"

    # Case Study Focus (Focus on dramatic comparisons and risks based on the company cases)
    st.markdown("ü¶∏ **Case Study Analysis: ABB, CNH, Vodafone**")
    col3, col4 = st.columns(2)

    with col3:
        if st.button("üõë Vodafone's Automation Strategy", key="case_q3_s7_modified"):
            if 'sample_question' not in st.session_state:
                st.session_state.sample_question = None
            # MODIFIED Question 3: Vodafone Case
            st.session_state.sample_question = "Vodafone's primary goal is to **'Automate and improve customer care.'** What are the three most critical **data and IT infrastructure capabilities** (e.g., cloud, AI/ML, centralized data lakes) required to achieve high-level automation in customer service, and how 10 building blocks of framework are critical for it?"

    with col4:
        if st.button("ü§ù ABB's 'Value' vs. CNH's 'Services' Goal", key="case_q4_s7_modified"):
            if 'sample_question' not in st.session_state:
                st.session_state.sample_question = None
            # MODIFIED Question 4: Comparing Digital Transformation Goals (Value vs. Services)
            st.session_state.sample_question = "ABB's goal is 'to create **continuous value** for customers through software-enabled services,' while CNH Industrial's goal is to 'develop new services around **predictive maintenance** and **intelligent logistics**.' How do these slightly different primary goals (broad 'value' vs. focused 'services') influence the scope, required investment, and desired timeline for their respective digital transformations?"

    # Class Preparation Questions (Focus on technical/operational details for cold calls)
    st.markdown("üìù **Class Preparation: Framework Application**")
    col5, col6 = st.columns(2)

    with col5:
        if st.button("‚öôÔ∏è Cold Call: Applying The Star Model‚Ñ¢", key="prep_q5_s7"):
            if 'sample_question' not in st.session_state:
                st.session_state.sample_question = None
            # Question 5: Application of The Star Model‚Ñ¢
            st.session_state.sample_question = "You are cold-called: **'If a company introduces a new digital product (Strategy) but its current IT department (Structure) is siloed, which other two elements of The Star Model‚Ñ¢ must be urgently realigned to avoid failure? Justify your choice with a real-world example.'**"

    with col6:
        if st.button("üìà Digital Maturity Metrics", key="prep_q6_s7"):
            if 'sample_question' not in st.session_state:
                st.session_state.sample_question = None
            # Question 6: Metrics and Transformation
            st.session_state.sample_question = "The 10-Step Framework emphasizes metrics. What is a key performance indicator (KPI) that measures **operational effectiveness** in a digital transformation, and how does it differ from a KPI that measures **customer value creation**?"

model = None

if api_key:
    try:
        if provider == "OpenAI" and api_key.startswith("sk-"):
            model = ChatOpenAI(
                api_key=api_key,
                model=model_name or "gpt-4o-mini",
                temperature=0.7
            )

       # elif provider == "Together":
       #     model = ChatTogether(
       #         together_api_key=api_key,
       #         model=model_name or "mistralai/Mistral-7B-Instruct-v0.2",
       #         temperature=0.7
       #     )

        elif provider == "Groq":
            model = ChatGroq(
                groq_api_key=api_key,
                model_name=model_name or "llama-3.1-8b-instant",
                temperature=0.7
            )

        elif provider == "Hugging Face":
            # Typical model e.g. "HuggingFaceH4/zephyr-7b-beta"
            model = ChatHuggingFace(
                huggingfacehub_api_token=api_key,
                repo_id=model_name or "HuggingFaceH4/zephyr-7b-beta",
                temperature=0.7
            )

        elif provider == "Anthropic" and api_key.startswith("sk-ant-"):
            model = ChatAnthropic(
                anthropic_api_key=api_key,
                model_name=model_name or "claude-3-haiku-20240307",
                temperature=0.7
            )

        elif provider == "Perplexity" and api_key.startswith("pplx-"):
            model = ChatPerplexity(
                api_key=api_key,
                model=model_name or "sonar-pro",
                temperature=0.7
            )
        else:
            st.error("Unsupported provider or invalid API key format.")
    except Exception as e:
        st.error(f"Error initializing model: {e}")

if model:
    
    embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    # Load vectorstore from disk instead of recreating it
    vectorstore = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embedding_model
    )

    # Cleaner parse_docs with expander
    def parse_docs(docs):
        return {"texts": docs}

    # Replace retriever with a RunnableLambda that does similarity_search
    def run_similarity_search(query):
        # k=5 to get top 5 docs, adjust as needed
        results = vectorstore.similarity_search(query, k=5)
        return results

    # Build prompt with expander
    def build_prompt(kwargs):
        ctx = kwargs["context"]
        question = kwargs["question"]
        context_text = "\n".join([d.page_content for d in ctx["texts"]])
        prompt_template = f"""
            Role: You are a helpful assistant for advance undergratuate students taking the Digital and AI strategy course. Your purpose is to help students understand the provided lecture notes and examples.
            Instructions:
            1.  Answer question only using the provided context. Do not use outside knowledge.
            2.  Maintain a polite and encouraging tone.
            3.  If a student asks a question that is not covered in the context, inform them that the question is outside the current topic of this session.
            4.  Suggest that they can search the web for more information if they are curious.
            5.  If a question is a duplicate, provide a more concise version of the previous answer.
            6.  Do not provide any in-text citations in your response without including reference list in the response.
            Context:
            {context_text}

            Question: {question}
            """

        return ChatPromptTemplate.from_messages(
            [{"role": "user", "content": prompt_template}]
        ).format_messages()

    # Compose chain using RunnableLambda for similarity_search + parse_docs
    chain = (
        {
            "context": itemgetter("question") | RunnableLambda(run_similarity_search) | RunnableLambda(parse_docs),
            "question": itemgetter("question")
        }
        | RunnableLambda(build_prompt)
        | model
        | StrOutputParser()
    )

    # Streamlit chat UI
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # Handle sample question selection
    pending_question = None
    if 'sample_question' in st.session_state and st.session_state.sample_question:
        pending_question = st.session_state.sample_question
        st.session_state.sample_question = None  # Clear it after using
    
    user_input = st.chat_input("Ask a question...")
    if user_input:
        pending_question = user_input
    
    if pending_question:
        # Add the question to messages
        st.session_state.messages.append({"role": "user", "content": pending_question})
        st.chat_message("user").write(pending_question)

        try:
            answer = chain.invoke({"question": pending_question})
            st.session_state.messages.append({"role": "assistant", "content": answer})
            st.chat_message("assistant").write(answer)
        except Exception as e:
            st.error(f"Error running RAG chain: {e}")
            st.error(traceback.format_exc())

else:
    # Handle sample question selection even without API key
    if 'sample_question' in st.session_state and st.session_state.sample_question:
        st.info(f"You selected: '{st.session_state.sample_question}' - Please enter your API key above to get an answer!")
        st.session_state.sample_question = None  # Clear it after showing
    
    st.warning("Please enter your API key and choose a provider.", icon="‚ö†")
